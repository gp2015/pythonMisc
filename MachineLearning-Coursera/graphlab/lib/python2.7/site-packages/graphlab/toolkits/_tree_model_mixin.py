import graphlab as gl
import graphlab.connect as _mt
from graphlab.toolkits._internal_utils import _raise_error_if_not_sframe
import graphlab.toolkits._main as _toolkits_main
from graphlab.toolkits._internal_utils import _map_unity_proxy_to_object


class TreeModelMixin(object):
    """
    Implements common methods among tree models:
    - BoostedTreesClassifier
    - BoostedTreesRegression
    - RandomForestClassifier
    - RandomForestRegression
    """

    def get_feature_importance(self):
        """
        Get the importance of features used by the model.

        The measure of importance of feature X
        is determined by the sum of occurence of X
        as a branching node in all trees.

        When X is a categorical feature, e.g. "Gender",
        the index column contains the value of the feature, e.g. "M" or "F".
        When X is a numerical feature, index of X is None.

        Return
        ------
        out : SFrame
            A table with three columns: name, index, count,
            ordered by 'count' in desending order.

        Examples
        --------
        >>> m.get_feature_importance()
        Rows: 31
        Data:
            +-----------------------------+-------+-------+
            |             name            | index | count |
            +-----------------------------+-------+-------+
            | DER_mass_transverse_met_lep |  None |   66  |
            |         DER_mass_vis        |  None |   65  |
            |          PRI_tau_pt         |  None |   61  |
            |         DER_mass_MMC        |  None |   59  |
            |      DER_deltar_tau_lep     |  None |   58  |
            |          DER_pt_tot         |  None |   41  |
            |           PRI_met           |  None |   38  |
            |     PRI_jet_leading_eta     |  None |   30  |
            |     DER_deltaeta_jet_jet    |  None |   27  |
            |       DER_mass_jet_jet      |  None |   24  |
            +-----------------------------+-------+-------+
            [31 rows x 3 columns]
        """
        metric_name = '.'.join([self.__module__, 'get_feature_importance'])
        _mt._get_metric_tracker().track(metric_name)
        return gl.extensions._xgboost_feature_importance(self.__proxy__)

    def extract_features(self, dataset):
        """
        For each example in the dataset, extract the leaf indices of
        each tree as features.

        For multiclass classification, each leaf index contains #num_class
        numbers.

        The returned feature vectors can be used as input to train another
        supervised learning model such as a
        :py:class:`~graphlab.logistic_classifier.LogisticClassifier`,
        an :py:class:`~graphlab.svm_classifier.SVMClassifier`, or a
        :py:class:`~graphlab.neuralnet_classifier.NeuralNetClassifier`.

        Parameters
        ----------
        dataset : SFrame
            Dataset of new observations. Must include columns with the same
            names as the features used for model training, but does not require
            a target column. Additional columns are ignored.

        Returns
        -------
        out : SArray
            An SArray of dtype array.array containing extracted features.

        Examples
        --------
        >>> data =  graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/regression/houses.csv')

        >>> # Regression Tree Models
        >>> model = graphlab.boosted_trees_regression.create(data,
        ...                           target='price',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['boosted_tree_features'] = model.extract_features(data)
        >>> model = graphlab.random_forest_regression.create(data,
        ...                           target='price',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['random_forest_features'] = model.extract_features(data)

        >>> # Classification Tree Models
        >>> data['is_expensive'] = data['price'] > 30000
        >>> model = graphlab.boosted_trees_classifier.create(data,
        ...                           target='is_expensive',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['boosted_tree_features'] = model.extract_features(data)

        >>> model = graphlab.random_forest_classifier.create(data,
        ...                           target='is_expensive',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['random_forest_features'] = model.extract_features(data)
        """
        metric_name = '.'.join([self.__module__, 'extract_features'])
        _mt._get_metric_tracker().track(metric_name)
        _raise_error_if_not_sframe(dataset, "dataset")
        options = dict()
        options.update({'model': self.__proxy__,
                        'model_name': self.__name__,
                        'dataset': dataset})
        target = _toolkits_main.run('supervised_learning_feature_extraction', options)
        return _map_unity_proxy_to_object(target['extracted'])

    def _dump_to_text(self, with_stats):
        """
        Dump the models into a list of strings. Each
        string is a text representation of a tree.

        Parameters
        ----------
        with_stats : bool
            If true, include node statistics in the output.

        Return
        ------
        out : SFrame
            A table with two columns: feature, count,
            ordered by 'count' in desending order.
        """
        return gl.extensions._xgboost_dump_model(self.__proxy__, with_stats)
